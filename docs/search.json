[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Principal Component Denoising (Whale Calls)",
    "section": "",
    "text": "1 Introduction\nMaritime technological advancements in recent years have enhanced marine mammal detection / surveying efforts. In particular, the introduction of passive and active bio-acoustic monitoring via buoy networks have allowed for the current shipping industry to identify optimal transport routes while minimizing the impact of commercial shipping on the ocean’s environment. One challenge that is frequently encountered in the efforts to identify the presence of marine mammals is the presence of heavy audio interference picked up by the deployed buoy microphones. The interference itself comes in many different forms, and as a result, efforts to train a model that can match human performance in the detection / labeling of said calls often encounter sub-optimal model performance issues. To this end, there exists a present gap in the state of the art for a denoising algorithm that operates pre-hoc (independent of model training). From this the motivation for our project is derived. We seek to use this project to propose an algorithmic solution to this issue and provide a visual exploration of the effects of our solution on the dataset to further dive into both the quality of the dataset and any further implications.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nThe data we will be using is comprised of 30,000 two-second .aiff audio files that have been converted to .png images. The audio itself was collected at a sample rate of 2kHz In addition, the observations (being any one such image) have a corresponding Boolean label in a csv file indicating whether or not the image actually contains a whale call.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\nInspection of the data folder indicates that all 30,000 of the training images to be used for the purposes of our analyses are included. Furthermore, we check for missingness in the dataframe containing the labels for our data points, and find that there is no missing data. This is unsurprising as the data was processed and distributed by a reputable Kaggle competition host.\n\n\nCode\nlibrary(glue)\n\ntraining_labels &lt;- read.csv(\"data/train.csv\")\nnumber_missing &lt;- sum(is.na(training_labels))\ncat(glue(\"Number of missing values: {number_missing}\\n\"))\n\n\nNumber of missing values: 0\n\n\nOne more key characteristic of the data we want to be concerned with is the class balance. That is, what is the ratio of images with a whale call contained within (label = 1) to the images without a call (label = 0)?\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\n# Assuming your DataFrame is named training_labels\nggplot(training_labels, aes(x = factor(label))) +\n  geom_bar() +\n  labs(\n    title = \"Distribution of Labels\",\n    x = \"Label\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\n\nObserve that the vast majority of observations do not contain a call. For our purposes, we will want to keep a small portion of the observations while adjusting for the class imbalance via under sampling.\nWe will keep 500 observations from each class and create a new random subset of the original dataset.\n\n\nCode\n# # Assuming your DataFrame is named training_labels\n# \n# # Subset the DataFrame into two groups: label == 0 and label == 1\n# label_0 &lt;- training_labels[training_labels$label == 0, ]\n# label_1 &lt;- training_labels[training_labels$label == 1, ]\n# \n# # Randomly sample 500 rows from each group\n# set.seed(123)  # For reproducibility\n# sampled_label_0 &lt;- label_0[sample(nrow(label_0), 500), ]\n# sampled_label_1 &lt;- label_1[sample(nrow(label_1), 500), ]\n# \n# # Combine the sampled subsets into a single DataFrame\n# sampled_training_labels &lt;- rbind(sampled_label_0, sampled_label_1)\n\n\nBelow is the code we use to delete the images in our data directory that do not have a label observation in our filtered subset dataframe.\n\n\nCode\n# # Set the working directory to where the .png files and train.csv are located\n# setwd(\"data/\")\n# \n# # Read the train.csv file\n# train_df &lt;- read.csv(\"train.csv\")\n# \n# # Extract the list of image names from train.csv\n# image_files_to_keep &lt;- train_df$image_name  # Adjust column name if necessary\n# \n# # Get the list of all .png files in the current directory\n# all_png_files &lt;- list.files(pattern = \"\\\\.png$\")\n# \n# # Identify files to delete (not in train.csv)\n# files_to_delete &lt;- setdiff(all_png_files, image_files_to_keep)\n# \n# # Delete the unwanted .png files\n# if (length(files_to_delete) &gt; 0) {\n#   file.remove(files_to_delete)\n#   message(length(files_to_delete), \" files deleted.\")\n# } else {\n#   message(\"No files to delete.\")\n# }",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "Below we present the application and analysis of our denoising algorithm on a smaller subset of the isolated dataset described in the data section of our write-up. We settled on 30 observations from each of the two labels, with 60 total in the subset for size limitations and purposes.\n\n3.0.0.1 The Idea\nIntuitively, our algorithm that we present below is isolating the signal components that are used to construct the original data matrix and denoising these signal components separately. Only then, do we reconstruct the original data matrix and conduct a standard column-wise median denoising. This way, any time-periodic fully invasive interference can be handled in an isolated fashion so as to preserve signal shape while providing a competent level of denoising.\n\n\n3.0.0.2 The Algorithm\nWe approach the denoising process as follows:\nThe denoising algorithm implemented in this analysis combines Principal Component Analysis (PCA) with a novel column-wise thresholding technique. The process can be broken down into several key steps.\n\n3.0.0.2.1 1. Initial Decomposition\nWe apply PCAA through Singular Value Decomposition to decompose the image matrix. Said decomposition yields three matrices, of which we are primarily concerned with the right-most containing the singular codomain vectors. The transpose of this matrix, call it V, represents the “building blocks” of our images. More specifically, the rows of \\(V^T\\) can be reshapedd into the n = 2 dimensional singular basis vectors used to reconstruct our original dataset.\n\n\n3.0.0.2.2 2. Column-wise Thresholding\nFor each principal component image (rows of \\(V^T\\)), our algorithm:\n\nReshapes the flattened vector into a 255 x 255 matrix (representative of it’s image vector form)\nProcesses each column independently\nApplies one of three thresholding approaches (median subtraction, 25th percentile subtraction, and 75th percentile subtraction)\n\nAny negative values resulting from the subtraction are set to 0. Then the processed matrix is flattened back into a row vector of the matrix \\(V^T\\).\n\n\n3.0.0.2.3 3. Image Reconstruction\nThe processed \\(V^T\\) matrix is used with the other 2 original matrices to reconstruct the original dataset. This reconstruction maintains the global structure while incorporating the denoising effects. Then we apply a final median value column-wise subtraction to the reconstructed images.\nBelow we provide an example of an image with a whale call signal before and after our denoising method (in particular, an iteration of a denoising path using median singular component thresholding).\n\n\nCode\nmatrix_copy &lt;- image_matrix\n\ncentered_matrix &lt;- scale(matrix_copy, center = TRUE, scale = FALSE)\n\nsvd_result &lt;- svd(centered_matrix)\n\nU &lt;- svd_result$u\n\nV &lt;- svd_result$v\n\nD &lt;- svd_result$d\n\nD_matrix &lt;- diag(D)\n\neigenvalues &lt;- D^2\n\npc_images &lt;- t(svd_result$v)\n\nreconstruction &lt;- U %*% D_matrix %*% pc_images\n\n\n\n\nCode\n# Function to process a single 255x255 matrix\nprocess_matrix &lt;- function(flat_vector, percentile_func) {\n  # Reshape to 255x255\n  img_matrix &lt;- matrix(flat_vector, nrow=255, ncol=255)\n  \n  # Process each column\n  for(j in 1:255) {\n    thresh_val &lt;- percentile_func(img_matrix[,j])\n    # Subtract threshold value and cap at 0\n    img_matrix[,j] &lt;- pmax(img_matrix[,j] - thresh_val, 0)\n  }\n  \n  # Return flattened processed matrix\n  return(as.vector(img_matrix))\n}\n\n\n# Apply to each row of pc_images\n\nprocessed_pc_images_median &lt;- matrix(0, nrow=60, ncol=65025)\n\nprocessed_pc_images_25th &lt;- matrix(0, nrow=60, ncol=65025)\n\nprocessed_pc_images_75th &lt;- matrix(0, nrow=60, ncol=65025)\n\n\nfor(i in 1:60) {\n  processed_pc_images_median[i,] &lt;- process_matrix(pc_images[i,], median)\n  \n  processed_pc_images_25th[i,] &lt;- process_matrix(pc_images[i,], function(x) quantile(x, 0.25))\n  \n  processed_pc_images_75th[i,] &lt;- process_matrix(pc_images[i,], function(x) quantile(x, 0.75))\n}\n\nreconstruction_median &lt;- svd_result$u %*% D_matrix %*% processed_pc_images_median\nreconstruction_25th &lt;- svd_result$u %*% D_matrix %*% processed_pc_images_25th\nreconstruction_75th &lt;- svd_result$u %*% D_matrix %*% processed_pc_images_75th\n\n\n\n# Function to apply median subtraction to a matrix\napply_median_subtraction &lt;- function(flat_matrix) {\n  # Reshape each row to 255x255, process, and flatten back\n  processed_matrix &lt;- matrix(0, nrow=nrow(flat_matrix), ncol=ncol(flat_matrix))\n  \n  for(i in 1:nrow(flat_matrix)) {\n    # Reshape to 255x255\n    img_matrix &lt;- matrix(flat_matrix[i,], nrow=255, ncol=255)\n    \n    # Process each column\n    for(j in 1:255) {\n      col_median &lt;- median(img_matrix[,j])\n      # Subtract median and cap at 0\n      img_matrix[,j] &lt;- pmax(img_matrix[,j] - col_median, 0)\n    }\n    \n    # Flatten and store\n    processed_matrix[i,] &lt;- as.vector(img_matrix)\n  }\n  \n  return(processed_matrix)\n}\n\n# Apply to each reconstruction\nfinal_median &lt;- apply_median_subtraction(reconstruction_median)\nfinal_25th &lt;- apply_median_subtraction(reconstruction_25th)\nfinal_75th &lt;- apply_median_subtraction(reconstruction_75th)\n\n\n\n\nCode\nimage_width = 255\nimage_height = 255\n\nfirst_image_vector &lt;- reconstruction[31, ]\nfirst_image_matrix &lt;- matrix(first_image_vector, nrow = image_width, ncol = image_height, byrow = FALSE)\nfirst_image_cimg &lt;- as.cimg(first_image_matrix)\n\n# Display the corrected first image\nplot(first_image_cimg, main = \"Before Denoising\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nfirst_image_vector &lt;- final_median[31, ]\nfirst_image_matrix &lt;- matrix(first_image_vector, nrow = image_width, ncol = image_height, byrow = FALSE)\nfirst_image_cimg &lt;- as.cimg(first_image_matrix)\n\n# Display the corrected first image\nplot(first_image_cimg, main = \"After Denoising\")\n\n\n\n\n\n\n\n\n\nAs we can see, to the human eye, the signal appears to be more isolated and in a cleaner, noiseless environment. However, we seek to analyze the performance of our denoising algorithm iterations objectively and compare them. Therefore we require an objective measurement for spectrogram image quality post processing, and to this end we use the traditional Signal-to-Noise ratio and Structural Similarity Index Measure metrics to gauge performance.\nSignal-to-Noise Ratio is calculated as:\n\\[\n\\text{SNR} = 10 \\cdot \\log_{10}\\left(\\frac{P_{\\text{signal}}}{P_{\\text{noise}}}\\right)\n\\]\nwhere\n\\[\nP_{\\text{signal}} = \\frac{1}{N}\\sum_{i=1}^{N} x_i^2\n\\]\n\\[\nP_{\\text{noise}} = \\frac{1}{N}\\sum_{i=1}^{N} (x_i - y_i)^2\n\\] Intuitively, SNR measures how much signal dominates over the background noise in an image. A higher SNR value generally means a signal is more prominent and distinguishable from the noise in the background, and therefore the denoising algorithm had a higher efficacy.\nStructural Similarity Index Measure (SSIM) is calculated to be\n\\[\n\\text{SSIM}(x,y) = \\frac{(2\\mu_x\\mu_y + c_1)(2\\sigma_{xy} + c_2)}{(\\mu_x^2 + \\mu_y^2 + c_1)(\\sigma_x^2 + \\sigma_y^2 + c_2)}\n\\]\nwhere\n\\[\n\\mu_x = \\frac{1}{N}\\sum_{i=1}^{N} x_i\n\\]\n\\[\n\\sigma_x^2 = \\frac{1}{N-1}\\sum_{i=1}^{N} (x_i - \\mu_x)^2\n\\]\n\\[\n\\sigma_{xy} = \\frac{1}{N-1}\\sum_{i=1}^{N} (x_i - \\mu_x)(y_i - \\mu_y)\n\\]\nSSIM measures how similar two images are in terms of their structure rather than just pixel by pixel differences. In order to ensure we preserve as much relevant signal structure as possible in the new image using our algorithm, we use this metric to gauge the proportion of the original structure preserved (values range from 0 to 1 where 1 is near perfect structure preservation).\nThese two metrics are calculated for each observation across all three methods and stored in separate dataframes for the purposes of exploring the state of the data as well as the performance of our algorithm below.\n\n\n\n3.0.0.3 Performance Analysis\nWe first graph histograms of the SNR and SSIM for each of the three thresholding intensities to observe the distribution of the data post hoc.\n\n\nCode\n# # Function to calculate SNR\n# calculate_snr &lt;- function(original, processed) {\n#   signal_power &lt;- mean(original^2)\n#   noise_power &lt;- mean((original - processed)^2)\n#   snr &lt;- 10 * log10(signal_power/noise_power)\n#   return(snr)\n# }\n# \n# # Helper functions for SSIM\n# calculate_mean &lt;- function(window) {\n#   return(mean(window))\n# }\n# \n# calculate_variance &lt;- function(window) {\n#   return(mean((window - mean(window))^2))\n# }\n# \n# calculate_covariance &lt;- function(window1, window2) {\n#   return(mean((window1 - mean(window1)) * (window2 - mean(window2))))\n# }\n# \n# # Function to calculate SSIM for a single window\n# calculate_window_ssim &lt;- function(window1, window2, k1 = 0.01, k2 = 0.03, L = 255) {\n#   # Constants\n#   c1 &lt;- (k1 * L)^2\n#   c2 &lt;- (k2 * L)^2\n#   \n#   # Calculate statistics\n#   mu1 &lt;- calculate_mean(window1)\n#   mu2 &lt;- calculate_mean(window2)\n#   sigma1_sq &lt;- calculate_variance(window1)\n#   sigma2_sq &lt;- calculate_variance(window2)\n#   sigma12 &lt;- calculate_covariance(window1, window2)\n#   \n#   # Calculate SSIM\n#   numerator &lt;- (2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)\n#   denominator &lt;- (mu1^2 + mu2^2 + c1) * (sigma1_sq + sigma2_sq + c2)\n#   \n#   return(numerator/denominator)\n# }\n# \n# # Function to calculate SSIM for entire image\n# calculate_ssim &lt;- function(original, processed, window_size = 11) {\n#   # Reshape to 255x255 matrices\n#   orig_mat &lt;- matrix(original, nrow=255, ncol=255)\n#   proc_mat &lt;- matrix(processed, nrow=255, ncol=255)\n#   \n#   ssim_values &lt;- c()\n#   \n#   # Calculate SSIM for each window\n#   for(i in 1:(255-window_size+1)) {\n#     for(j in 1:(255-window_size+1)) {\n#       window1 &lt;- orig_mat[i:(i+window_size-1), j:(j+window_size-1)]\n#       window2 &lt;- proc_mat[i:(i+window_size-1), j:(j+window_size-1)]\n#       ssim_values &lt;- c(ssim_values, calculate_window_ssim(window1, window2))\n#     }\n#   }\n#   \n#   # Return mean SSIM\n#   return(mean(ssim_values))\n# }\n# \n# # Create empty dataframes for each percentile\n# metrics_median &lt;- data.frame(\n#   image_index = 1:60,\n#   snr = numeric(60),\n#   ssim = numeric(60)\n# )\n# \n# metrics_25th &lt;- data.frame(\n#   image_index = 1:60,\n#   snr = numeric(60),\n#   ssim = numeric(60)\n# )\n# \n# metrics_75th &lt;- data.frame(\n#   image_index = 1:60,\n#   snr = numeric(60),\n#   ssim = numeric(60)\n# )\n# \n# # Calculate metrics for each image in each version\n# for(i in 1:60) {\n#   # For median version\n#   metrics_median$snr[i] &lt;- calculate_snr(centered_matrix[i,], final_median[i,])\n#   metrics_median$ssim[i] &lt;- calculate_ssim(centered_matrix[i,], final_median[i,])\n#   \n#   # For 25th percentile version\n#   metrics_25th$snr[i] &lt;- calculate_snr(centered_matrix[i,], final_25th[i,])\n#   metrics_25th$ssim[i] &lt;- calculate_ssim(centered_matrix[i,], final_25th[i,])\n#   \n#   # For 75th percentile version\n#   metrics_75th$snr[i] &lt;- calculate_snr(centered_matrix[i,], final_75th[i,])\n#   metrics_75th$ssim[i] &lt;- calculate_ssim(centered_matrix[i,], final_75th[i,])\n#   \n#   # Print progress\n#   if(i %% 10 == 0) {\n#     print(paste(\"Processed\", i, \"images\"))\n#   }\n# }\n\n\n\n\nCode\n# write.csv(metrics_median, \"../data/metrics_median.csv\", row.names = FALSE)\n# write.csv(metrics_25th, \"../data/metrics_25th.csv\", row.names = FALSE)\n# write.csv(metrics_75th, \"../data/metrics_75th.csv\", row.names = FALSE)\n\nmetrics_median &lt;- read.csv(\"data/metrics_median.csv\")\nmetrics_25th &lt;- read.csv(\"data/metrics_25th.csv\")\nmetrics_75th &lt;- read.csv(\"data/metrics_75th.csv\")\n\n\n\n\nCode\n# SNR and SSIM histograms for each method arranged by rows\n# Median row\np1 &lt;- ggplot(metrics_median, aes(x=snr)) + \n  geom_histogram(fill=\"skyblue\", bins=10) +\n  scale_x_continuous(breaks = seq(floor(min(metrics_median$snr)), ceiling(max(metrics_median$snr)), by=0.5)) +\n  ggtitle(\"Median: SNR\") +\n  theme_minimal()\n\np2 &lt;- ggplot(metrics_median, aes(x=ssim)) + \n  geom_histogram(fill=\"skyblue\", bins=10) +\n  scale_x_continuous(breaks = seq(round(min(metrics_median$ssim), 4), round(max(metrics_median$ssim), 4), by=0.0025)) +\n  ggtitle(\"Median: SSIM\") +\n  theme_minimal()\n\n# 25th Percentile row\np3 &lt;- ggplot(metrics_25th, aes(x=snr)) + \n  geom_histogram(fill=\"lightgreen\", bins=10) +\n  scale_x_continuous(breaks = seq(floor(min(metrics_25th$snr)), ceiling(max(metrics_25th$snr)), by=0.5)) +\n  ggtitle(\"25th Percentile: SNR\") +\n  theme_minimal()\n\np4 &lt;- ggplot(metrics_25th, aes(x=ssim)) + \n  geom_histogram(fill=\"lightgreen\", bins=10) +\n  scale_x_continuous(breaks = seq(round(min(metrics_25th$ssim), 4), round(max(metrics_25th$ssim), 4), by=0.0025)) +\n  ggtitle(\"25th Percentile: SSIM\") +\n  theme_minimal()\n\n# 75th Percentile row\np5 &lt;- ggplot(metrics_75th, aes(x=snr)) + \n  geom_histogram(fill=\"salmon\", bins=10) +\n  scale_x_continuous(breaks = seq(floor(min(metrics_75th$snr)), ceiling(max(metrics_75th$snr)), by=0.5)) +\n  ggtitle(\"75th Percentile: SNR\") +\n  theme_minimal()\n\np6 &lt;- ggplot(metrics_75th, aes(x=ssim)) + \n  geom_histogram(fill=\"salmon\", bins=10) +\n  scale_x_continuous(breaks = seq(round(min(metrics_75th$ssim), 4), round(max(metrics_75th$ssim), 4), by=0.0025)) +\n  ggtitle(\"75th Percentile: SSIM\") +\n  theme_minimal()\n\n# Arrange plots with methods in rows\ngrid.arrange(p1, p3, p5, p2, p4, p6, nrow=2)\n\n\n\n\n\n\n\n\n\nAs we can see, all three methods tend to display the potential presence of two subpopulations in the data when SNR is calculated while the SSIM values gauging signal preservation seem relatively unimodal and consistent between the three methods. We suspected the bimodal nature of the SNR distributions for all strengths to be attributed to the labels in the data (whether an image contains a signal or not) and therefore overlayed new histograms to observe if grouping by label would procure a suggested answer for what is causing this shape. Note that in our data matrix, by our preprocessing methods, the FIRST 30 observations had no signal (label = 0) and the LAST 30 observations contained a signal (label = 1).\n\n\nCode\ncreate_split_histograms &lt;- function(data, title_prefix) {\n  # Split data\n  first30 &lt;- data[1:30,]\n  last30 &lt;- data[31:60,]\n  \n  # SNR plot with aligned breaks\n  p1 &lt;- ggplot() + \n    geom_histogram(data=first30, aes(x=snr, fill=\"First 30\"), bins=15, alpha=0.6) +\n    geom_histogram(data=last30, aes(x=snr, fill=\"Last 30\"), bins=15, alpha=0.6) +\n    scale_fill_manual(values=c(\"First 30\"=\"skyblue\", \"Last 30\"=\"salmon\")) +\n    scale_x_continuous(breaks = seq(floor(min(data$snr)), ceiling(max(data$snr)), by=0.5)) +\n    ggtitle(paste(title_prefix, \"- SNR\")) +\n    theme_minimal() +\n    labs(fill=\"Group\")\n\n  # SSIM plot with aligned breaks\n  p2 &lt;- ggplot() + \n    geom_histogram(data=first30, aes(x=ssim, fill=\"First 30\"), bins=15, alpha=0.6) +\n    geom_histogram(data=last30, aes(x=ssim, fill=\"Last 30\"), bins=15, alpha=0.6) +\n    scale_fill_manual(values=c(\"First 30\"=\"skyblue\", \"Last 30\"=\"salmon\")) +\n    scale_x_continuous(breaks = seq(round(min(data$ssim), 4), round(max(data$ssim), 4), by=0.0025)) +\n    ggtitle(paste(title_prefix, \"- SSIM\")) +\n    theme_minimal() +\n    labs(fill=\"Group\")\n    \n  return(list(p1, p2))\n}\n\n# Create plots for each percentile\nmedian_plots &lt;- create_split_histograms(metrics_median, \"Median\")\np25_plots &lt;- create_split_histograms(metrics_25th, \"25th Percentile\")\np75_plots &lt;- create_split_histograms(metrics_75th, \"75th Percentile\")\n\n# Arrange all plots in a grid\ngrid.arrange(\n  median_plots[[1]], median_plots[[2]],\n  p25_plots[[1]], p25_plots[[2]],\n  p75_plots[[1]], p75_plots[[2]],\n  ncol=2\n)\n\n\n\n\n\n\n\n\n\nAs we can see, it is at least virtually clear that the distribution for signal-containing images across all denoising intensities procured a shape with higher SNR center value than that of the images with no signals. This, while we have not yet tested statistically for certain whether the difference is significant, makes sense because our SNR calculation procures values of near 0 for multiple reasons, one of which being that there is no high intensity pixel value in the post-hoc image to inflate the numerator of the calculation. Judging by our SSIM distributions for all three intensities, since the data tends extremely towards 1, we can say that the structural integrity of our signals is fairly well preserved on an objective level. We draw similar conclusions based on the boxplots given below.\n\n\nCode\n# Function to prepare data\nprepare_data &lt;- function(df, method_name) {\n  df$Method &lt;- method_name\n  df$Group &lt;- ifelse(df$image_index &lt;= 30, \"No Signal\", \"Signal\")\n  return(df)\n}\n\n# Combine all data\nall_data &lt;- rbind(\n  prepare_data(metrics_median, \"Median\"),\n  prepare_data(metrics_25th, \"25th Percentile\"),\n  prepare_data(metrics_75th, \"75th Percentile\")\n)\n\n# Create SNR boxplot\np1 &lt;- ggplot(all_data, aes(x=Method, y=snr, fill=Group)) +\n  geom_boxplot() +\n  ggtitle(\"SNR Distribution by Method and Group\") +\n  theme_minimal() +\n  scale_fill_manual(values=c(\"No Signal\"=\"skyblue\", \"Signal\"=\"salmon\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Create SSIM boxplot\np2 &lt;- ggplot(all_data, aes(x=Method, y=ssim, fill=Group)) +\n  geom_boxplot() +\n  ggtitle(\"SSIM Distribution by Method and Group\") +\n  theme_minimal() +\n  scale_fill_manual(values=c(\"No Signal\"=\"skyblue\", \"Signal\"=\"salmon\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Arrange plots\ngrid.arrange(p1, p2, ncol=2)\n\n\n\n\n\n\n\n\n\nNext, observe the results of difference in mean hypothesis tests for the signal vs no-signal distribution centers across all three intensities. In every case, we reject the null that there is no significant difference between signal containing images and their anitheses observations. Further, we conduct an ANOVA test to determine the presence of a difference in performance between the denoising intensities. We find that the SNR calculations are significantly different between all 3 methods but SSIM is generally indistinguishable on average. More specifically, the 25th percentile intensity appears to be more objectively powerful at creating a distinguishing barrier between signal and noise in an image.\n\n\nCode\n# T-tests for Signal vs No Signal in each method\n# For Median method\nt_med_snr &lt;- t.test(snr ~ Group, data=subset(all_data, Method==\"Median\"))\nt_med_ssim &lt;- t.test(ssim ~ Group, data=subset(all_data, Method==\"Median\"))\n\n# For 25th Percentile\nt_25_snr &lt;- t.test(snr ~ Group, data=subset(all_data, Method==\"25th Percentile\"))\nt_25_ssim &lt;- t.test(ssim ~ Group, data=subset(all_data, Method==\"25th Percentile\"))\n\n# For 75th Percentile\nt_75_snr &lt;- t.test(snr ~ Group, data=subset(all_data, Method==\"75th Percentile\"))\nt_75_ssim &lt;- t.test(ssim ~ Group, data=subset(all_data, Method==\"75th Percentile\"))\n\n# ANOVA to compare methods\nsnr_anova &lt;- aov(snr ~ Method, data=all_data)\nssim_anova &lt;- aov(ssim ~ Method, data=all_data)\n\n# Print results\ncat(\"T-test results for Signal vs No Signal:\\n\\n\")\n\n\nT-test results for Signal vs No Signal:\n\n\nCode\ncat(\"Median Method:\\n\")\n\n\nMedian Method:\n\n\nCode\ncat(\"SNR: p-value =\", t_med_snr$p.value, \"\\n\")\n\n\nSNR: p-value = 0.003668359 \n\n\nCode\ncat(\"SSIM: p-value =\", t_med_ssim$p.value, \"\\n\\n\")\n\n\nSSIM: p-value = 1.691642e-05 \n\n\nCode\ncat(\"25th Percentile Method:\\n\")\n\n\n25th Percentile Method:\n\n\nCode\ncat(\"SNR: p-value =\", t_25_snr$p.value, \"\\n\")\n\n\nSNR: p-value = 0.005980776 \n\n\nCode\ncat(\"SSIM: p-value =\", t_25_ssim$p.value, \"\\n\\n\")\n\n\nSSIM: p-value = 2.475448e-05 \n\n\nCode\ncat(\"75th Percentile Method:\\n\")\n\n\n75th Percentile Method:\n\n\nCode\ncat(\"SNR: p-value =\", t_75_snr$p.value, \"\\n\")\n\n\nSNR: p-value = 0.002908904 \n\n\nCode\ncat(\"SSIM: p-value =\", t_75_ssim$p.value, \"\\n\\n\")\n\n\nSSIM: p-value = 1.007325e-05 \n\n\nCode\ncat(\"ANOVA results comparing methods:\\n\")\n\n\nANOVA results comparing methods:\n\n\nCode\ncat(\"SNR: \")\n\n\nSNR: \n\n\nCode\nsummary(snr_anova)\n\n\n             Df Sum Sq Mean Sq F value  Pr(&gt;F)    \nMethod        2  20.04  10.021   17.93 8.1e-08 ***\nResiduals   177  98.91   0.559                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nCode\ncat(\"\\nSSIM: \")\n\n\n\nSSIM: \n\n\nCode\nsummary(ssim_anova)\n\n\n             Df   Sum Sq   Mean Sq F value Pr(&gt;F)\nMethod        2 6.00e-07 3.188e-07   0.135  0.874\nResiduals   177 4.18e-04 2.362e-06               \n\n\nOne more interesting visualization we offer is a scatter plot (for each percentile method) comparing the values of the calculated SNR vs the SSIM. Observe that there is a positive correlation between SNR and SSIM up to a certain threshold after which there is a logistic leveling effect. Signal groups tend to cluster in the upper-right quadrant of the graph region (high SNR, high SSIM) whereas no signal groups show more variability / dispersion in both metrics.\n\n\nCode\n# Create scatter plots for each percentile method\np1 &lt;- ggplot() + \n  geom_point(data=metrics_median, aes(x=snr, y=ssim, color=ifelse(image_index &lt;= 30, \"No Signal\", \"Signal\")), size=3, alpha=0.6) +\n  ggtitle(\"Median: SNR vs SSIM\") +\n  scale_color_manual(values=c(\"No Signal\"=\"skyblue\", \"Signal\"=\"salmon\")) +\n  theme_minimal() +\n  labs(color=\"Group\")\n\np2 &lt;- ggplot() + \n  geom_point(data=metrics_25th, aes(x=snr, y=ssim, color=ifelse(image_index &lt;= 30, \"No Signal\", \"Signal\")), size=3, alpha=0.6) +\n  ggtitle(\"25th Percentile: SNR vs SSIM\") +\n  scale_color_manual(values=c(\"No Signal\"=\"skyblue\", \"Signal\"=\"salmon\")) +\n  theme_minimal() +\n  labs(color=\"Group\")\n\np3 &lt;- ggplot() + \n  geom_point(data=metrics_75th, aes(x=snr, y=ssim, color=ifelse(image_index &lt;= 30, \"No Signal\", \"Signal\")), size=3, alpha=0.6) +\n  ggtitle(\"75th Percentile: SNR vs SSIM\") +\n  scale_color_manual(values=c(\"No Signal\"=\"skyblue\", \"Signal\"=\"salmon\")) +\n  theme_minimal() +\n  labs(color=\"Group\")\n\n# Arrange plots\ngrid.arrange(p1, p2, p3, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nCode\n# # Combine and prepare the data\n# combined_metrics &lt;- rbind(\n#   transform(metrics_median, method = \"Median\"),\n#   transform(metrics_25th, method = \"25th Percentile\"),\n#   transform(metrics_75th, method = \"75th Percentile\")\n# )\n# combined_metrics$group &lt;- ifelse(combined_metrics$image_index &lt;= 30, \"No Signal\", \"Signal\")\n# \n# # Export to JSON\n# library(jsonlite)\n# json_data &lt;- toJSON(combined_metrics, pretty=TRUE)\n# writeLines(json_data, \"metrics_data.json\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "5  Conclusion",
    "section": "",
    "text": "Based on our analysis, we can draw several important conclusions. Firstly, our denoising algorithm is effective across all three variants. That is, by isolating signal generating components and cleaning them separately first before reconstruction and further cleaning works towards creating denoised spectrograms with high structural clarity and integrity. Furthermore, there is a clear structural difference between signal-present and signal-absent images. In the future, this project will see great value in exploring the potential of introducing signal-absent images that contain man-made interference that have a clear structural presence, thereby potentially changing our current opinion of the state of difference between whale-call having images and whale-call absent images. This approach however, is rather computationally intensive and limited, especially when more granular percentile intensities are proposed to clean the singular components. Hence a necessary direction of research will be that of exploring algorithm optimization for our solution. However, we reiterate the overall success of our algorithm, and highly encourage further customization and or exploration of the bioacoustic data universe using our denoising method.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  }
]